{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f4ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import math\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(192837)\n",
    "rand = random.Random(192838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db0a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_COLUMN = 'city_ascii'\n",
    "COUNTRY_COLUMN = 'iso2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d78a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.6100</td>\n",
       "      <td>77.2300</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>admin</td>\n",
       "      <td>32226000.0</td>\n",
       "      <td>1356872604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.0761</td>\n",
       "      <td>72.8775</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>admin</td>\n",
       "      <td>24973000.0</td>\n",
       "      <td>1356226629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kolkāta</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>22.5675</td>\n",
       "      <td>88.3700</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>admin</td>\n",
       "      <td>21747000.0</td>\n",
       "      <td>1356060520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>12.9789</td>\n",
       "      <td>77.5917</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Karnātaka</td>\n",
       "      <td>admin</td>\n",
       "      <td>15386000.0</td>\n",
       "      <td>1356410365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>13.0825</td>\n",
       "      <td>80.2750</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Tamil Nādu</td>\n",
       "      <td>admin</td>\n",
       "      <td>12395000.0</td>\n",
       "      <td>1356374944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>17.3617</td>\n",
       "      <td>78.4747</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Telangāna</td>\n",
       "      <td>admin</td>\n",
       "      <td>10494000.0</td>\n",
       "      <td>1356871768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Pune</td>\n",
       "      <td>Pune</td>\n",
       "      <td>18.5203</td>\n",
       "      <td>73.8567</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8231000.0</td>\n",
       "      <td>1356081074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>23.0225</td>\n",
       "      <td>72.5714</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Gujarāt</td>\n",
       "      <td>minor</td>\n",
       "      <td>8009000.0</td>\n",
       "      <td>1356304381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Sūrat</td>\n",
       "      <td>Surat</td>\n",
       "      <td>21.2050</td>\n",
       "      <td>72.8400</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Gujarāt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6538000.0</td>\n",
       "      <td>1356758738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Prayagraj</td>\n",
       "      <td>Prayagraj</td>\n",
       "      <td>25.4358</td>\n",
       "      <td>81.8464</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5954391.0</td>\n",
       "      <td>1356718332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city city_ascii      lat      lng country iso2 iso3     admin_name  \\\n",
       "2       Delhi      Delhi  28.6100  77.2300   India   IN  IND          Delhi   \n",
       "4      Mumbai     Mumbai  19.0761  72.8775   India   IN  IND    Mahārāshtra   \n",
       "10    Kolkāta    Kolkata  22.5675  88.3700   India   IN  IND    West Bengal   \n",
       "21  Bangalore  Bangalore  12.9789  77.5917   India   IN  IND      Karnātaka   \n",
       "29    Chennai    Chennai  13.0825  80.2750   India   IN  IND     Tamil Nādu   \n",
       "39  Hyderābād  Hyderabad  17.3617  78.4747   India   IN  IND      Telangāna   \n",
       "55       Pune       Pune  18.5203  73.8567   India   IN  IND    Mahārāshtra   \n",
       "58  Ahmedabad  Ahmedabad  23.0225  72.5714   India   IN  IND        Gujarāt   \n",
       "79      Sūrat      Surat  21.2050  72.8400   India   IN  IND        Gujarāt   \n",
       "90  Prayagraj  Prayagraj  25.4358  81.8464   India   IN  IND  Uttar Pradesh   \n",
       "\n",
       "   capital  population          id  \n",
       "2    admin  32226000.0  1356872604  \n",
       "4    admin  24973000.0  1356226629  \n",
       "10   admin  21747000.0  1356060520  \n",
       "21   admin  15386000.0  1356410365  \n",
       "29   admin  12395000.0  1356374944  \n",
       "39   admin  10494000.0  1356871768  \n",
       "55     NaN   8231000.0  1356081074  \n",
       "58   minor   8009000.0  1356304381  \n",
       "79     NaN   6538000.0  1356758738  \n",
       "90     NaN   5954391.0  1356718332  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('../emb/data/worldcities.csv')\n",
    "\n",
    "'''\n",
    "df_top_countries = df_all.groupby(COUNTRY_COLUMN).size().sort_values(ascending=False).reset_index()\n",
    "classes = list(df_top_countries.head(N_CLASSES)[COUNTRY_COLUMN])\n",
    "'''\n",
    "classes = ['IN']\n",
    "N_CLASSES = len(classes)\n",
    "\n",
    "print(classes)\n",
    "class_to_id = {classes[i]: i for i in range(N_CLASSES)}\n",
    "\n",
    "df_all = df_all[df_all[COUNTRY_COLUMN].isin(classes)]\n",
    "df_all = df_all[df_all[CITY_COLUMN].notna()]\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1911a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD> -ABCDEFGHIJKLMNOPQRSTUVWYZabcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_set = set()\n",
    "for city in df_all[CITY_COLUMN]:\n",
    "    for ch in city:\n",
    "        character_set.add(ch)\n",
    "\n",
    "PAD_TOKEN = 0\n",
    "tokens = ['<PAD>'] + sorted(list(character_set))\n",
    "token_to_id = {tokens[i]: i for i in range(len(tokens))}\n",
    "N_VOCAB = len(tokens)\n",
    "\n",
    "''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef52e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(city: str, max_length: int):\n",
    "    encoded = [token_to_id[city[i]] for i in range(min(max_length, len(city)))]\n",
    "    return encoded + [PAD_TOKEN] * (max_length - len(encoded))\n",
    "\n",
    "def decode(city_enc: list[int], decode_special: bool=False):\n",
    "    return ''.join([tokens[tk] for tk in city_enc if (tk != PAD_TOKEN or decode_special)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e92e0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_length_90_perc = np.quantile(np.array(list(map(len, df_all[CITY_COLUMN]))), 0.8)\n",
    "\n",
    "SEQ_LENGTH = int(city_length_90_perc)\n",
    "SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8bbf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barah IN\n",
      "Chittaurgar IN\n",
      "Bhogpur IN\n",
      "Jami IN\n",
      "Bhadreswar IN\n",
      "7108 6397 711\n"
     ]
    }
   ],
   "source": [
    "data_list_x = [encode(city, SEQ_LENGTH) for city in df_all[CITY_COLUMN]]\n",
    "data_list_y = [class_to_id[iso2] for iso2 in df_all[COUNTRY_COLUMN]]\n",
    "data_list = list(zip(data_list_x, data_list_y))\n",
    "rand.shuffle(data_list)\n",
    "\n",
    "data_x = torch.tensor(np.array([x for x, _ in data_list], dtype=np.long))\n",
    "data_y = torch.tensor(np.array([y for _, y in data_list], dtype=np.long))\n",
    "\n",
    "for i in range(5):\n",
    "    print(decode(data_x[i]), classes[data_y[i]])\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "n_train = round(data_x.shape[0] * TRAIN_TEST_SPLIT)\n",
    "train_x, train_y = data_x[:n_train, :], data_y[:n_train]\n",
    "test_x,  test_y  = data_x[n_train:, :], data_y[n_train:]\n",
    "\n",
    "print(data_x.shape[0], n_train, data_x.shape[0] - n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa598a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNGenerator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 hidden_layers: int=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Linear(N_VOCAB, emb_dim, bias=False)\n",
    "\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, num_layers=hidden_layers, batch_first=True)\n",
    "        self.head_1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.head_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.head_3 = nn.Linear(hidden_dim, N_VOCAB)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if len(x.shape) == 2:  # unbatched input\n",
    "            x = x.unsqueeze(0)\n",
    "        B, *_ = x.shape\n",
    "\n",
    "        x = self.emb(x)\n",
    "        rnn_o, h_n = self.rnn(x)\n",
    "        o = self.relu(self.head_1(rnn_o))\n",
    "        o = self.relu(self.head_2(o))\n",
    "        o = self.head_3(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e366abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: nn.Module,\n",
    "                optimizer: optim.Optimizer,\n",
    "                dataset_x: torch.Tensor,\n",
    "                batch_size: int):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    accu_sum = 0\n",
    "    n_batches = math.ceil(dataset_x.shape[0] / batch_size)\n",
    "\n",
    "    for i in tqdm.tqdm(range(n_batches), 'train'):\n",
    "        x = dataset_x[i * batch_size: (i+1) * batch_size, :]\n",
    "        x_oh = F.one_hot(x, N_VOCAB).to(dtype=torch.float32)\n",
    "        x_hat = model.forward(x_oh)\n",
    "\n",
    "        # DEBUG\n",
    "        # print(x.shape, x_oh.shape, x_hat.shape)\n",
    "\n",
    "        loss = F.cross_entropy(x_hat[:, :-1, :].reshape((-1, N_VOCAB)), x[:, 1:].reshape((-1,)), ignore_index=PAD_TOKEN)\n",
    "        loss_sum += loss.detach().clone()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            accu_sum += torch.sum(x_hat[:, :-1, :].argmax(dim=-1) == x[:, 1:]) / x.shape[0] / (x.shape[1] - 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return loss_sum / n_batches, accu_sum / n_batches\n",
    "\n",
    "def test_epoch(model: nn.Module, dataset_x: torch.Tensor, batch_size):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        accu_sum = 0\n",
    "        n_batches = math.ceil(dataset_x.shape[0] / batch_size)\n",
    "\n",
    "        for i in tqdm.tqdm(range(n_batches), ' test'):\n",
    "            x = dataset_x[i * batch_size: (i+1) * batch_size, :]\n",
    "            x_oh = F.one_hot(x, N_VOCAB).to(dtype=torch.float32)\n",
    "            x_hat = model.forward(x_oh)\n",
    "\n",
    "            loss = F.cross_entropy(x_hat[:, :-1, :].reshape((-1, N_VOCAB)), x[:, 1:].reshape((-1,)), ignore_index=PAD_TOKEN)\n",
    "            loss_sum += loss\n",
    "            accu_sum += torch.sum(x_hat[:, :-1, :].argmax(dim=-1) == x[:, 1:]) / x.shape[0] / (x.shape[1] - 1)\n",
    "\n",
    "        return loss_sum / n_batches, accu_sum / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1705ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNGenerator(emb_dim=16,\n",
    "                     hidden_dim=32,\n",
    "                     hidden_layers=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-5)\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d94872db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.90it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 373.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.0323071479797363\n",
      " test loss: 2.7356069087982178\n",
      "train accu: 0.1586713343858719\n",
      " test accu: 0.18144410848617554\n",
      "=== epoch 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 72.12it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 372.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.5660009384155273\n",
      " test loss: 2.3441948890686035\n",
      "train accu: 0.20120632648468018\n",
      " test accu: 0.23051242530345917\n",
      "=== epoch 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.56it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 391.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.332127332687378\n",
      " test loss: 2.2992665767669678\n",
      "train accu: 0.23267507553100586\n",
      " test accu: 0.2343944013118744\n",
      "=== epoch 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 70.30it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 388.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.2909586429595947\n",
      " test loss: 2.2617979049682617\n",
      "train accu: 0.2345096468925476\n",
      " test accu: 0.24194489419460297\n",
      "=== epoch 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.87it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 363.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.263923406600952\n",
      " test loss: 2.2380614280700684\n",
      "train accu: 0.23623929917812347\n",
      " test accu: 0.24468167126178741\n",
      "=== epoch 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 73.88it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 297.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.244938850402832\n",
      " test loss: 2.2206871509552\n",
      "train accu: 0.23732484877109528\n",
      " test accu: 0.2437305897474289\n",
      "=== epoch 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:03<00:00, 60.38it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 364.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.2305305004119873\n",
      " test loss: 2.2073850631713867\n",
      "train accu: 0.23786106705665588\n",
      " test accu: 0.24481754004955292\n",
      "=== epoch 7 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:03<00:00, 64.02it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 247.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.219320058822632\n",
      " test loss: 2.1974446773529053\n",
      "train accu: 0.23842662572860718\n",
      " test accu: 0.24623450636863708\n",
      "=== epoch 8 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 66.96it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 321.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.209426164627075\n",
      " test loss: 2.188187837600708\n",
      "train accu: 0.23925799131393433\n",
      " test accu: 0.24767084419727325\n",
      "=== epoch 9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 69.94it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 355.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.196610927581787\n",
      " test loss: 2.173112392425537\n",
      "train accu: 0.24101123213768005\n",
      " test accu: 0.25215449929237366\n",
      "=== epoch 10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 70.18it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 392.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.173067092895508\n",
      " test loss: 2.1501963138580322\n",
      "train accu: 0.24801774322986603\n",
      " test accu: 0.25677406787872314\n",
      "=== epoch 11 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 74.07it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 334.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.1455719470977783\n",
      " test loss: 2.1282620429992676\n",
      "train accu: 0.2547381520271301\n",
      " test accu: 0.2628299593925476\n",
      "=== epoch 12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 72.76it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 330.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.125689744949341\n",
      " test loss: 2.113877058029175\n",
      "train accu: 0.25893041491508484\n",
      " test accu: 0.26554736495018005\n",
      "=== epoch 13 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 71.32it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 364.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.1121699810028076\n",
      " test loss: 2.102344512939453\n",
      "train accu: 0.26182594895362854\n",
      " test accu: 0.2641110122203827\n",
      "=== epoch 14 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 74.59it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 365.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.1020190715789795\n",
      " test loss: 2.0944716930389404\n",
      "train accu: 0.262419730424881\n",
      " test accu: 0.26335409283638\n",
      "=== epoch 15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 73.44it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 329.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0934860706329346\n",
      " test loss: 2.0868020057678223\n",
      "train accu: 0.2634822130203247\n",
      " test accu: 0.26389750838279724\n",
      "=== epoch 16 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.51it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 328.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0859527587890625\n",
      " test loss: 2.0807011127471924\n",
      "train accu: 0.26426514983177185\n",
      " test accu: 0.26457688212394714\n",
      "=== epoch 17 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 73.67it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 375.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0786633491516113\n",
      " test loss: 2.07452130317688\n",
      "train accu: 0.2649196982383728\n",
      " test accu: 0.26512032747268677\n",
      "=== epoch 18 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.57it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 335.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.071485757827759\n",
      " test loss: 2.0683367252349854\n",
      "train accu: 0.26549622416496277\n",
      " test accu: 0.2660714089870453\n",
      "=== epoch 19 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.40it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 357.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0646533966064453\n",
      " test loss: 2.0625202655792236\n",
      "train accu: 0.2662181556224823\n",
      " test accu: 0.2684588134288788\n",
      "=== epoch 20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 73.93it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 385.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.058098793029785\n",
      " test loss: 2.058354139328003\n",
      "train accu: 0.2664526104927063\n",
      " test accu: 0.26919642090797424\n",
      "=== epoch 21 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.31it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 383.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0519065856933594\n",
      " test loss: 2.0540802478790283\n",
      "train accu: 0.2672995626926422\n",
      " test accu: 0.2696816623210907\n",
      "=== epoch 22 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.94it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 350.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0459368228912354\n",
      " test loss: 2.0501859188079834\n",
      "train accu: 0.2685808539390564\n",
      " test accu: 0.2691381871700287\n",
      "=== epoch 23 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 74.24it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 364.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0401549339294434\n",
      " test loss: 2.046708106994629\n",
      "train accu: 0.26897141337394714\n",
      " test accu: 0.2685947120189667\n",
      "=== epoch 24 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 72.39it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 308.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0342981815338135\n",
      " test loss: 2.042804002761841\n",
      "train accu: 0.27014654874801636\n",
      " test accu: 0.2695458233356476\n",
      "=== epoch 25 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 67.46it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 367.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0285372734069824\n",
      " test loss: 2.039987564086914\n",
      "train accu: 0.270865261554718\n",
      " test accu: 0.26962345838546753\n",
      "=== epoch 26 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 71.13it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 397.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0229663848876953\n",
      " test loss: 2.0361270904541016\n",
      "train accu: 0.271335631608963\n",
      " test accu: 0.271195650100708\n",
      "=== epoch 27 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 71.63it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 342.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0172502994537354\n",
      " test loss: 2.032392740249634\n",
      "train accu: 0.2722263038158417\n",
      " test accu: 0.27364128828048706\n",
      "=== epoch 28 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.59it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 327.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0114941596984863\n",
      " test loss: 2.0280659198760986\n",
      "train accu: 0.27344658970832825\n",
      " test accu: 0.27459239959716797\n",
      "=== epoch 29 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.81it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 397.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.005596876144409\n",
      " test loss: 2.024137020111084\n",
      "train accu: 0.2742278277873993\n",
      " test accu: 0.27546587586402893\n",
      "=== epoch 30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.92it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 319.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9999995231628418\n",
      " test loss: 2.020784616470337\n",
      "train accu: 0.2749137878417969\n",
      " test accu: 0.27560168504714966\n",
      "=== epoch 31 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.96it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 356.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.994636058807373\n",
      " test loss: 2.0174386501312256\n",
      "train accu: 0.2764310836791992\n",
      " test accu: 0.2773680090904236\n",
      "=== epoch 32 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.20it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 365.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.98944890499115\n",
      " test loss: 2.0137839317321777\n",
      "train accu: 0.27730441093444824\n",
      " test accu: 0.2783190608024597\n",
      "=== epoch 33 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.97it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 375.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9845402240753174\n",
      " test loss: 2.0106406211853027\n",
      "train accu: 0.2780856788158417\n",
      " test accu: 0.2781831920146942\n",
      "=== epoch 34 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 72.53it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 369.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.979685664176941\n",
      " test loss: 2.007685422897339\n",
      "train accu: 0.27900758385658264\n",
      " test accu: 0.27503880858421326\n",
      "=== epoch 35 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 72.56it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 358.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.975180983543396\n",
      " test loss: 2.0045664310455322\n",
      "train accu: 0.2802763879299164\n",
      " test accu: 0.27558231353759766\n",
      "=== epoch 36 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 74.11it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 352.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9704474210739136\n",
      " test loss: 2.002554416656494\n",
      "train accu: 0.28108885884284973\n",
      " test accu: 0.2772127389907837\n",
      "=== epoch 37 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 73.36it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 350.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.966017484664917\n",
      " test loss: 1.9993489980697632\n",
      "train accu: 0.2820263206958771\n",
      " test accu: 0.27585408091545105\n",
      "=== epoch 38 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 77.55it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 348.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9617438316345215\n",
      " test loss: 1.9972224235534668\n",
      "train accu: 0.2827155590057373\n",
      " test accu: 0.27503886818885803\n",
      "=== epoch 39 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.35it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 374.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.957587480545044\n",
      " test loss: 1.994613766670227\n",
      "train accu: 0.2836061418056488\n",
      " test accu: 0.27571818232536316\n",
      "=== epoch 40 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 74.29it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 382.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.953540325164795\n",
      " test loss: 1.9922764301300049\n",
      "train accu: 0.2846199870109558\n",
      " test accu: 0.2768051028251648\n",
      "=== epoch 41 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 74.86it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 350.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9495657682418823\n",
      " test loss: 1.9895766973495483\n",
      "train accu: 0.28549182415008545\n",
      " test accu: 0.27897903323173523\n",
      "=== epoch 42 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 76.64it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 346.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9456897974014282\n",
      " test loss: 1.98690927028656\n",
      "train accu: 0.2863200008869171\n",
      " test accu: 0.2812888026237488\n",
      "=== epoch 43 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.48it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 387.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9420208930969238\n",
      " test loss: 1.984712839126587\n",
      "train accu: 0.28689974546432495\n",
      " test accu: 0.28033772110939026\n",
      "=== epoch 44 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.82it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 329.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9382902383804321\n",
      " test loss: 1.9824978113174438\n",
      "train accu: 0.2873232960700989\n",
      " test accu: 0.2829386591911316\n",
      "=== epoch 45 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 69.22it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 355.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9345935583114624\n",
      " test loss: 1.9806784391403198\n",
      "train accu: 0.2877139747142792\n",
      " test accu: 0.2829386591911316\n",
      "=== epoch 46 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.20it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 306.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9309440851211548\n",
      " test loss: 1.978567361831665\n",
      "train accu: 0.28863751888275146\n",
      " test accu: 0.2833462655544281\n",
      "=== epoch 47 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 75.96it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 348.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9272695779800415\n",
      " test loss: 1.9765784740447998\n",
      "train accu: 0.2894498407840729\n",
      " test accu: 0.284297376871109\n",
      "=== epoch 48 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 77.39it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 370.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.923789381980896\n",
      " test loss: 1.9746588468551636\n",
      "train accu: 0.2900296151638031\n",
      " test accu: 0.2837538421154022\n",
      "=== epoch 49 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 200/200 [00:02<00:00, 77.09it/s]\n",
      " test: 100%|██████████| 23/23 [00:00<00:00, 372.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9203715324401855\n",
      " test loss: 1.9723210334777832\n",
      "train accu: 0.29088738560676575\n",
      " test accu: 0.2835403382778168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(N_EPOCHS):\n",
    "    print(f'=== epoch {epoch_i} ===')\n",
    "\n",
    "    train_loss, train_accu = train_epoch(model, optimizer, train_x, BATCH_SIZE)\n",
    "    test_loss, test_accu = test_epoch(model, test_x, BATCH_SIZE)\n",
    "\n",
    "    print('train loss:', train_loss.item())\n",
    "    print(' test loss:', test_loss.item())\n",
    "    print('train accu:', train_accu.item())\n",
    "    print(' test accu:', test_accu.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "389f809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moschaurika\n",
      "Rio Manjunk\n",
      "Delhadinghe\n",
      "Shaniharcha\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "for test in ('Mosc', 'Rio ', 'Delh', 'Shan'):\n",
    "    test_tokens = encode(test, 4)\n",
    "    test_tokens = torch.tensor(test_tokens, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    for i in range(4, SEQ_LENGTH):\n",
    "        pred = model.forward(F.one_hot(test_tokens, N_VOCAB).to(torch.float32))\n",
    "        dist = Categorical(logits=pred[:, -1, :])\n",
    "        next_tokens = dist.sample().unsqueeze(1)\n",
    "\n",
    "        test_tokens = torch.cat((test_tokens, next_tokens), dim=-1)\n",
    "\n",
    "    print(decode(test_tokens.squeeze(), decode_special=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4972585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "from torch.distributions.gumbel import Gumbel\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "class AntiRNNGen():\n",
    "    def __init__(self,\n",
    "                 inner_net: nn.Module,\n",
    "                 initial_tokens: int=6,\n",
    "                 desired_tokens: str='abc',\n",
    "                 lr: float=1e-2,\n",
    "                 right_c_coef: float=1.0,\n",
    "                 wrong_c_coef: float=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_initial_tokens = initial_tokens\n",
    "        self.n_desired_tokens = len(desired_tokens)\n",
    "        self.desired_tokens = [token_to_id[ch] for ch in desired_tokens]\n",
    "        self.desired_tokens = torch.tensor(self.desired_tokens, dtype=torch.long)\n",
    "\n",
    "        self.input_shape = (1, initial_tokens, N_VOCAB)\n",
    "        self.input = nn.Parameter(\n",
    "            data=torch.normal(0, 1, size=self.input_shape),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.inner_net = inner_net\n",
    "        self.grad_eraser = torch.optim.SGD(self.inner_net.parameters())\n",
    "        self.anti_optimizer = torch.optim.Adam((self.input,), lr=lr)\n",
    "        # self.anti_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "        self.right_c_coef = right_c_coef\n",
    "        self.wrong_c_coef = wrong_c_coef\n",
    "\n",
    "        # self.input_min = 0.0\n",
    "        # self.input_max = 1.0\n",
    "\n",
    "        self.gumbel = Gumbel(loc=0.0, scale=1.0)\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            return self.inner_net.forward(self.input)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.grad_eraser.zero_grad()\n",
    "        self.anti_optimizer.zero_grad()\n",
    "\n",
    "    # def crop(self):\n",
    "    #     self.input.data.copy_(torch.clamp(self.input.detach().clone(), self.input_min, self.input_max))\n",
    "    \n",
    "    def step(self):\n",
    "        prev_input = self.input.detach().clone()\n",
    "\n",
    "        probs = torch.softmax(self.input, dim=-1)\n",
    "\n",
    "        extra_tokens = torch.zeros((1, self.n_desired_tokens - 1, N_VOCAB))\n",
    "        extra_tokens[0, torch.arange(0, self.n_desired_tokens - 1), self.desired_tokens[:-1]] = 1.0\n",
    "        probs = torch.cat((probs, extra_tokens), dim=1)\n",
    "\n",
    "        gumb = self.gumbel.sample(probs.shape)\n",
    "\n",
    "        j_onehot = F.one_hot(torch.argmax(gumb + torch.log(probs + self.epsilon), dim=-1), N_VOCAB)\n",
    "        j_onehot = j_onehot.to(torch.float32).requires_grad_(True)\n",
    "\n",
    "        j_continuous = torch.softmax(gumb + torch.log(probs + self.epsilon), dim=-1)\n",
    "\n",
    "        output = self.inner_net.forward(j_onehot)\n",
    "        output_soft = torch.softmax(output, dim=-1)\n",
    "        \n",
    "        # DEBUG\n",
    "        # print(j_onehot.shape, j_continuous.shape, output.shape, output_soft.shape)\n",
    "\n",
    "        loss = output_soft[:, self.n_initial_tokens - 1: self.n_initial_tokens + self.n_desired_tokens - 1, :]\\\n",
    "                          [torch.arange(0, N_VOCAB).unsqueeze(0).unsqueeze(1) != self.desired_tokens.unsqueeze(0).unsqueeze(2)]\\\n",
    "            .sum() * self.wrong_c_coef + \\\n",
    "               output_soft[:, self.n_initial_tokens - 1: self.n_initial_tokens + self.n_desired_tokens - 1, :]\\\n",
    "                          [:, :, self.desired_tokens].sum() * -self.right_c_coef\n",
    "        loss.backward()\n",
    "\n",
    "        j_continuous.backward(j_onehot.grad)\n",
    "\n",
    "        self.anti_optimizer.step()\n",
    "        self.zero_grad()\n",
    "\n",
    "        # self.anti_scheduler.step()\n",
    "\n",
    "        # self.crop()\n",
    "\n",
    "        return prev_input, output.detach().clone(), loss.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc1acc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=- step 0 -=-=-\n",
      "desired tokens: pal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:27<00:00, 110.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 1.3960310220718384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:26<00:00, 114.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: -0.5257922410964966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:25<00:00, 119.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 1.3415793180465698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:25<00:00, 117.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 1.4076471328735352\n",
      "fin loss: -0.5257922410964966\n",
      "fin input: EZuyAY\n",
      "fin output (from function): rarampal\n",
      "fin output (argmax sample): EZuyAYpal\n",
      "fin output (random sample): EZuyAYali\n",
      "-=-=- step 1 -=-=-\n",
      "desired tokens: pur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:25<00:00, 115.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: -0.8369953632354736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:25<00:00, 117.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: -1.128077507019043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:25<00:00, 117.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: -0.5411638021469116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:27<00:00, 110.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: -0.9788793325424194\n",
      "fin loss: -1.128077507019043\n",
      "fin input: dURToT\n",
      "fin output (from function): inaaaaur\n",
      "fin output (argmax sample): dURToTpur\n",
      "fin output (random sample): dURToT La\n",
      "-=-=- step 2 -=-=-\n",
      "desired tokens: ana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:25<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: -1.155346155166626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:25<00:00, 119.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: -1.3665924072265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:25<00:00, 115.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: -1.3541224002838135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:25<00:00, 117.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: -1.2274953126907349\n",
      "fin loss: -1.3665924072265625\n",
      "fin input: CncaMR\n",
      "fin output (from function): hihiaapa\n",
      "fin output (argmax sample): CncaMRapu\n",
      "fin output (random sample): CncaMRuru\n",
      "-=-=- step 3 -=-=-\n",
      "desired tokens: tia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:25<00:00, 116.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 0.5438131093978882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:25<00:00, 116.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 0.032302141189575195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:25<00:00, 117.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 1.1580132246017456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:25<00:00, 116.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 0.020190954208374023\n",
      "fin loss: 0.020190954208374023\n",
      "fin input: FAcQMR\n",
      "fin output (from function): aahaaaia\n",
      "fin output (argmax sample): FAcQMRagh\n",
      "fin output (random sample): FAcQMRana\n",
      "-=-=- step 4 -=-=-\n",
      "desired tokens: ish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:25<00:00, 117.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 1.6670098304748535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:26<00:00, 111.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 1.6715195178985596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:33<00:00, 89.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 0.5110284090042114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:29<00:00, 102.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 1.665529727935791\n",
      "fin loss: 0.5110284090042114\n",
      "fin input: gwwwvq\n",
      "fin output (from function): aaaaaiih\n",
      "fin output (argmax sample): gwwwvqiin\n",
      "fin output (random sample): gwwwvqied\n",
      "-=-=- step 5 -=-=-\n",
      "desired tokens: ika\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:26<00:00, 111.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 1.8541810512542725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:28<00:00, 105.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 0.695175290107727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:33<00:00, 90.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 1.769472360610962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:32<00:00, 91.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 1.4867336750030518\n",
      "fin loss: 0.695175290107727\n",
      "fin input: IVbH-R\n",
      "fin output (from function): laaanaaa\n",
      "fin output (argmax sample): IVbH-Ramp\n",
      "fin output (random sample): IVbH-Ruri\n",
      "-=-=- step 6 -=-=-\n",
      "desired tokens: ung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:28<00:00, 104.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 1.0059199333190918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:25<00:00, 117.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 1.4877104759216309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:24<00:00, 121.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 1.436935544013977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:29<00:00, 100.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 1.522752285003662\n",
      "fin loss: 1.0059199333190918\n",
      "fin input: qLqSEp\n",
      "fin output (from function): uaiaaurd\n",
      "fin output (argmax sample): qLqSEppal\n",
      "fin output (random sample): qLqSEpkhu\n",
      "-=-=- step 7 -=-=-\n",
      "desired tokens: cha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:40<00:00, 73.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 0.1935443878173828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:43<00:00, 69.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: -0.4566993713378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:43<00:00, 69.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: -0.4763883352279663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:45<00:00, 65.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: -0.5307084321975708\n",
      "fin loss: -0.5307084321975708\n",
      "fin input: EnlY w\n",
      "fin output (from function): rdaaraha\n",
      "fin output (argmax sample): EnlY wall\n",
      "fin output (random sample): EnlY wani\n"
     ]
    }
   ],
   "source": [
    "ANTI_NET_STEPS = 3000\n",
    "TEST_TRIES = 4\n",
    "TESTS = ('pal', 'pur', 'ana', 'tia', 'ish', 'ika', 'ung', 'cha')\n",
    "\n",
    "for i in range(len(TESTS)):\n",
    "    n_desired_tokens = 3\n",
    "    desired_tokens = TESTS[i]\n",
    "\n",
    "    print(f'-=-=- step {i} -=-=-')\n",
    "    print(f'desired tokens:', desired_tokens)\n",
    "\n",
    "    fin_loss = float('+inf')\n",
    "    fin_inp, fin_outp = None, None\n",
    "\n",
    "    for try_i in range(TEST_TRIES):\n",
    "        anti_net = AntiRNNGen(model, initial_tokens=6, desired_tokens=desired_tokens, lr=5e-2)\n",
    "\n",
    "        for step_i in tqdm.tqdm(range(ANTI_NET_STEPS), f'attempt #{try_i}'):\n",
    "            inp, outp, loss = anti_net.step()\n",
    "        \n",
    "        if loss.item() < fin_loss:\n",
    "            fin_loss = loss.item()\n",
    "            fin_inp = inp\n",
    "            fin_outp = outp\n",
    "        \n",
    "        print(f'attempt #{try_i} loss:', loss.item())\n",
    "    \n",
    "    print(f'fin loss:', fin_loss)\n",
    "    print(f'fin input:', decode(fin_inp.argmax(dim=-1).squeeze()))\n",
    "    print(f'fin output (from function):', decode(fin_outp.argmax(dim=-1).squeeze(), decode_special=True))\n",
    "    \n",
    "    outp_gen = fin_inp.argmax(dim=-1)\n",
    "    for i in range(n_desired_tokens):\n",
    "        pred = model.forward(F.one_hot(outp_gen, N_VOCAB).to(torch.float32))\n",
    "        next_tokens = pred[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "        outp_gen = torch.cat((outp_gen, next_tokens), dim=-1)\n",
    "\n",
    "    print(f'fin output (argmax sample):', decode(outp_gen.squeeze(), decode_special=True))\n",
    "\n",
    "    outp_gen = fin_inp.argmax(dim=-1)\n",
    "    for i in range(n_desired_tokens):\n",
    "        pred = model.forward(F.one_hot(outp_gen, N_VOCAB).to(torch.float32))\n",
    "\n",
    "        dist = Categorical(logits=pred[:, -1, :])\n",
    "        next_tokens = dist.sample().unsqueeze(1)\n",
    "\n",
    "        outp_gen = torch.cat((outp_gen, next_tokens), dim=-1)\n",
    "\n",
    "    print(f'fin output (random sample):', decode(outp_gen.squeeze(), decode_special=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
