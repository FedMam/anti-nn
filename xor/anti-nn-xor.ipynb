{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d8a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "torch.manual_seed(192837)\n",
    "rand = random.Random(192838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f079231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xorer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_digits: int=4,\n",
    "                 hidden_dim: int=16,\n",
    "                 hidden_layers: int=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.foot = nn.Linear(n_digits * 2, hidden_dim)\n",
    "        self.body = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(hidden_layers)])\n",
    "        self.head = nn.Linear(hidden_dim, n_digits)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.foot(x))\n",
    "        for l in self.body:\n",
    "            x = self.relu(l(x))\n",
    "        x = self.sigm(self.head(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91202b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bitvec(n: int, dim: int):\n",
    "    return [(1 if ((n & (1 << b)) != 0) else 0) for b in range(dim)]\n",
    "\n",
    "def from_bitvec(bits: list[int]):\n",
    "    return sum([bits[b] * (1 << b) for b in range(len(bits))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7f760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 230 26\n",
      "torch.Size([230, 8]) torch.Size([26, 8]) torch.Size([230, 4]) torch.Size([26, 4])\n"
     ]
    }
   ],
   "source": [
    "DIGITS = 4\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "\n",
    "dataset_full = [(to_bitvec(i, DIGITS) + to_bitvec(j, DIGITS), to_bitvec(i ^ j, DIGITS)) for i in range(2 ** DIGITS) for j in range(2 ** DIGITS)]\n",
    "rand.shuffle(dataset_full)\n",
    "dataset_x, dataset_y = zip(*dataset_full)\n",
    "dataset_x = torch.tensor(dataset_x, dtype=torch.float32)\n",
    "dataset_y = torch.tensor(dataset_y, dtype=torch.float32)\n",
    "\n",
    "n_full = len(dataset_full)\n",
    "n_train = round(n_full * TRAIN_TEST_SPLIT)\n",
    "n_test = n_full - n_train\n",
    "\n",
    "train_x, test_x = dataset_x[:n_train, :], dataset_x[n_train:, :]\n",
    "train_y, test_y = dataset_y[:n_train, :], dataset_y[n_train:, :]\n",
    "\n",
    "print(n_full, n_train, n_test)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4efd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.binary_cross_entropy\n",
    "\n",
    "def train_epoch(model: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                dataset_x: torch.Tensor,\n",
    "                dataset_y: torch.Tensor,\n",
    "                batch_size: int,\n",
    "                epoch_i: int,\n",
    "                verbose: bool=False):\n",
    "    model.train()\n",
    "\n",
    "    n_batches = math.ceil(dataset_x.shape[0] / batch_size)\n",
    "    loss_sum = 0.\n",
    "    accu_sum = 0.\n",
    "\n",
    "    for batch_i in tqdm.tqdm(range(n_batches), f'epoch {epoch_i} train') if verbose else range(n_batches):\n",
    "        x = dataset_x[batch_i * batch_size:(batch_i + 1) * batch_size, :]\n",
    "        y = dataset_y[batch_i * batch_size:(batch_i + 1) * batch_size, :]\n",
    "\n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            accu = (torch.round(y_hat) == y).to(torch.float32).mean()\n",
    "            accu_sum += accu.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "    \n",
    "    if verbose:\n",
    "        print('train loss:', loss_sum / n_batches)\n",
    "        print('train accu:', accu_sum / n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7977b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model: nn.Module,\n",
    "               dataset_x: torch.Tensor,\n",
    "               dataset_y: torch.Tensor,\n",
    "               batch_size: int,\n",
    "               epoch_i: int,\n",
    "               verbose: bool=False):\n",
    "    model.train()\n",
    "\n",
    "    n_batches = math.ceil(dataset_x.shape[0] / batch_size)\n",
    "    loss_sum = 0.\n",
    "    accu_sum = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_i in tqdm.tqdm(range(n_batches), f'epoch {epoch_i} test') if verbose else range(n_batches):\n",
    "            x = dataset_x[batch_i * batch_size:(batch_i + 1) * batch_size, :]\n",
    "            y = dataset_y[batch_i * batch_size:(batch_i + 1) * batch_size, :]\n",
    "\n",
    "            y_hat = model.forward(x)\n",
    "\n",
    "            loss = loss_fn(y_hat, y)\n",
    "\n",
    "            accu = (torch.round(y_hat) == y).to(torch.float32).mean()\n",
    "            accu_sum += accu.item()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "    if verbose:\n",
    "        print(' test loss:', loss_sum / n_batches)\n",
    "        print(' test accu:', accu_sum / n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd99636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xorer(DIGITS, hidden_dim=16, hidden_layers=3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "BATCH_SIZE = 8\n",
    "N_EPOCHS = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c4dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19 train: 100%|██████████| 29/29 [00:00<00:00, 398.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5226443749049614\n",
      "train accu: 0.6339798857425821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19 test: 100%|██████████| 4/4 [00:00<00:00, 1550.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.5279723852872849\n",
      " test accu: 0.5859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 39 train: 100%|██████████| 29/29 [00:00<00:00, 473.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3899604729537306\n",
      "train accu: 0.7464080452919006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 39 test: 100%|██████████| 4/4 [00:00<00:00, 2070.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.3831762298941612\n",
      " test accu: 0.8203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 59 train: 100%|██████████| 29/29 [00:00<00:00, 313.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3468946084893983\n",
      "train accu: 0.7543103448275862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 59 test: 100%|██████████| 4/4 [00:00<00:00, 1529.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.3575332835316658\n",
      " test accu: 0.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 79 train: 100%|██████████| 29/29 [00:00<00:00, 422.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.33313157948954353\n",
      "train accu: 0.807471265052927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 79 test: 100%|██████████| 4/4 [00:00<00:00, 1303.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.33757051080465317\n",
      " test accu: 0.8203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 99 train: 100%|██████████| 29/29 [00:00<00:00, 383.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.28392662056561174\n",
      "train accu: 0.8415948275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 99 test: 100%|██████████| 4/4 [00:00<00:00, 2128.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.27776307612657547\n",
      " test accu: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 119 train: 100%|██████████| 29/29 [00:00<00:00, 380.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2369566986273075\n",
      "train accu: 0.8591954029839615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 119 test: 100%|██████████| 4/4 [00:00<00:00, 2278.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.21687819436192513\n",
      " test accu: 0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 139 train: 100%|██████████| 29/29 [00:00<00:00, 378.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.19757787831898393\n",
      "train accu: 0.8706896551724138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 139 test: 100%|██████████| 4/4 [00:00<00:00, 1372.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.1925189271569252\n",
      " test accu: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 159 train: 100%|██████████| 29/29 [00:00<00:00, 435.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18245429057499457\n",
      "train accu: 0.8803879310344828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 159 test: 100%|██████████| 4/4 [00:00<00:00, 1722.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.18502729013562202\n",
      " test accu: 0.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 179 train: 100%|██████████| 29/29 [00:00<00:00, 450.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.17742835139406138\n",
      "train accu: 0.884698275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 179 test: 100%|██████████| 4/4 [00:00<00:00, 1696.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.18196140602231026\n",
      " test accu: 0.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 199 train: 100%|██████████| 29/29 [00:00<00:00, 460.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.17477212692129201\n",
      "train accu: 0.8857758620689655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 199 test: 100%|██████████| 4/4 [00:00<00:00, 1874.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.17926020175218582\n",
      " test accu: 0.8515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 219 train: 100%|██████████| 29/29 [00:00<00:00, 448.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.17001581089249973\n",
      "train accu: 0.9008620689655172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 219 test: 100%|██████████| 4/4 [00:00<00:00, 1456.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.17398091033101082\n",
      " test accu: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 239 train: 100%|██████████| 29/29 [00:00<00:00, 428.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.15274754680436234\n",
      "train accu: 0.9285201142574179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 239 test: 100%|██████████| 4/4 [00:00<00:00, 1493.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.15468808263540268\n",
      " test accu: 0.9296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 259 train: 100%|██████████| 29/29 [00:00<00:00, 455.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1064619008323242\n",
      "train accu: 0.9608477004643144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 259 test: 100%|██████████| 4/4 [00:00<00:00, 1864.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.11499328725039959\n",
      " test accu: 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 279 train: 100%|██████████| 29/29 [00:00<00:00, 347.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.032847051283922686\n",
      "train accu: 0.9989224137931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 279 test: 100%|██████████| 4/4 [00:00<00:00, 2297.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.04868536302819848\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 299 train: 100%|██████████| 29/29 [00:00<00:00, 581.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.005735184547716174\n",
      "train accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 299 test: 100%|██████████| 4/4 [00:00<00:00, 2538.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.009878653916530311\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 319 train: 100%|██████████| 29/29 [00:00<00:00, 619.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0018325320360700376\n",
      "train accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 319 test: 100%|██████████| 4/4 [00:00<00:00, 1855.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.0038806755328550935\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 339 train: 100%|██████████| 29/29 [00:00<00:00, 557.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.00034466537933973277\n",
      "train accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 339 test: 100%|██████████| 4/4 [00:00<00:00, 1731.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.004731532484584022\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 359 train: 100%|██████████| 29/29 [00:00<00:00, 579.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0001853805578289682\n",
      "train accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 359 test: 100%|██████████| 4/4 [00:00<00:00, 2222.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.003388426994206384\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 379 train: 100%|██████████| 29/29 [00:00<00:00, 472.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.00012019582673333232\n",
      "train accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 379 test: 100%|██████████| 4/4 [00:00<00:00, 2162.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.0026088613722095033\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 399 train: 100%|██████████| 29/29 [00:00<00:00, 537.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 8.585623637090663e-05\n",
      "train accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 399 test: 100%|██████████| 4/4 [00:00<00:00, 2074.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test loss: 0.0020974984818167286\n",
      " test accu: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(N_EPOCHS):\n",
    "    train_epoch(model, optimizer, train_x, train_y, BATCH_SIZE, epoch_i, verbose=(epoch_i + 1) % 20 == 0)\n",
    "    test_epoch(model, test_x, test_y, BATCH_SIZE, epoch_i, verbose=(epoch_i + 1) % 20 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a63300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "class AntiNet():\n",
    "    def __init__(self,\n",
    "               inner_net: nn.Module,\n",
    "               input_shape: torch.Size,\n",
    "               desired_output: torch.Tensor,\n",
    "               input_min: float,\n",
    "               input_max: float,\n",
    "               lr: float=1e-2,\n",
    "               temp_start: float=1.0,\n",
    "               temp_end: float=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.input = nn.Parameter(\n",
    "            data=torch.normal(0, 1, size=input_shape, dtype=torch.float32),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.inner_net = inner_net\n",
    "        self.grad_eraser = torch.optim.SGD(self.inner_net.parameters())\n",
    "        self.anti_optimizer = torch.optim.Adam((self.input,), lr=lr)\n",
    "        self.anti_scheduler = CosineAnnealingWarmRestarts(self.anti_optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "        self.desired_output = desired_output\n",
    "        self.output_shape = self.desired_output.shape\n",
    "\n",
    "        self.input_min = input_min\n",
    "        self.input_max = input_max\n",
    "\n",
    "        self.temp_start = temp_start\n",
    "        self.temp_end = temp_end\n",
    "        self.norm_func = lambda t: torch.softmax(t, dim=-1)\n",
    "\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            return self.inner_net.forward(self.norm_func(self.input / self.temp_end))\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.grad_eraser.zero_grad()\n",
    "        self.anti_optimizer.zero_grad()\n",
    "\n",
    "    # def crop(self):\n",
    "    #     self.input.data.copy_(torch.clamp(self.input.detach().clone(), self.input_min, self.input_max))\n",
    "\n",
    "    def parabolic_loss(self, t: torch.Tensor):\n",
    "        return (t * (1 - t)).sum()\n",
    "\n",
    "    def step(self, step_i: int, max_steps: int):\n",
    "        prev_input = self.input.detach().clone()\n",
    "\n",
    "        inp_soft = self.norm_func(self.input / (self.temp_start + (self.temp_end - self.temp_start) / (max_steps - 1) * step_i))\n",
    "\n",
    "        output = self.inner_net.forward(inp_soft)\n",
    "        loss = F.binary_cross_entropy(output, self.desired_output) \\\n",
    "            + self.parabolic_loss(inp_soft)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.anti_optimizer.step()\n",
    "        self.zero_grad()\n",
    "\n",
    "        self.anti_scheduler.step()\n",
    "\n",
    "        # self.crop()\n",
    "\n",
    "        return prev_input, output.detach().clone(), loss.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78772ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=- step 0 -=-=-\n",
      "desired output: tensor([0., 0., 1., 0.])\n",
      "example  input: tensor([1., 1., 1., 0., 1., 1., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:08<00:00, 367.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 0.00014561894931830466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:07<00:00, 395.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 27.003427505493164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:07<00:00, 415.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 3.7856283597648144e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:07<00:00, 383.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 0.00014561894931830466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #4: 100%|██████████| 3000/3000 [00:07<00:00, 426.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #4 loss: 3.7856283597648144e-05\n",
      "fin input: tensor([-2.9811, -2.9342,  3.6652, -2.5261, -3.2043, -1.8895, -2.1527,  1.1669])\n",
      "fin input (sigm): tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.9982e-22])\n",
      "fin output: tensor([3.8542e-08, 1.1380e-04, 1.0000e+00, 3.7337e-05])\n",
      "fin loss: 3.7856283597648144e-05\n",
      "-=-=- step 1 -=-=-\n",
      "desired output: tensor([0., 1., 0., 1.])\n",
      "example  input: tensor([0., 1., 1., 0., 0., 0., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:06<00:00, 434.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 29.3837947845459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:06<00:00, 429.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 2.43985652923584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:06<00:00, 435.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 0.6091113090515137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:06<00:00, 435.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 0.3952809274196625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #4: 100%|██████████| 3000/3000 [00:06<00:00, 429.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #4 loss: 2.43985652923584\n",
      "fin input: tensor([-2.2744,  3.4352, -1.0701, -2.0347, -1.9277, -1.0020, -1.1020,  3.4918])\n",
      "fin input (sigm): tensor([0.0000e+00, 2.4364e-01, 1.7957e-40, 0.0000e+00, 0.0000e+00, 7.0097e-40,\n",
      "        9.4917e-41, 7.5636e-01])\n",
      "fin output: tensor([8.8354e-06, 8.9879e-01, 2.1240e-17, 9.9983e-01])\n",
      "fin loss: 0.3952809274196625\n",
      "-=-=- step 2 -=-=-\n",
      "desired output: tensor([1., 1., 0., 1.])\n",
      "example  input: tensor([1., 1., 1., 1., 0., 0., 1., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:06<00:00, 438.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 3.7890193462371826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:08<00:00, 338.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 3.7890193462371826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:08<00:00, 344.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 3.7890193462371826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:09<00:00, 313.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 1.9875338077545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #4: 100%|██████████| 3000/3000 [00:07<00:00, 377.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #4 loss: 3.7890143394470215\n",
      "fin input: tensor([ 2.7783, -1.9592, -1.7953,  2.7620, -2.3868,  1.7359, -3.1499, -1.5535])\n",
      "fin input (sigm): tensor([5.8055e-01, 4.1226e-42, 1.0926e-40, 4.1945e-01, 1.4013e-45, 5.1269e-10,\n",
      "        0.0000e+00, 1.3764e-38])\n",
      "fin output: tensor([1.0000e+00, 2.5913e-03, 1.2181e-11, 9.5459e-01])\n",
      "fin loss: 1.9875338077545166\n",
      "-=-=- step 3 -=-=-\n",
      "desired output: tensor([0., 0., 1., 1.])\n",
      "example  input: tensor([1., 1., 0., 1., 1., 1., 1., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:07<00:00, 383.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 2.5016441345214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:08<00:00, 335.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 2.5489070415496826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:08<00:00, 338.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 9.471370697021484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:08<00:00, 349.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 2.5016441345214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #4: 100%|██████████| 3000/3000 [00:06<00:00, 443.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #4 loss: 0.37424036860466003\n",
      "fin input: tensor([-3.5766, -1.1691,  2.3928, -1.1910,  2.3336, -1.4651, -3.1458, -1.1934])\n",
      "fin input (sigm): tensor([0.0000e+00, 8.8374e-32, 7.6546e-01, 5.7021e-32, 2.3454e-01, 2.3709e-34,\n",
      "        0.0000e+00, 5.4255e-32])\n",
      "fin output: tensor([4.5975e-08, 3.9457e-04, 1.0000e+00, 9.4147e-01])\n",
      "fin loss: 0.37424036860466003\n",
      "-=-=- step 4 -=-=-\n",
      "desired output: tensor([1., 0., 1., 0.])\n",
      "example  input: tensor([1., 1., 0., 0., 0., 1., 1., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #0: 100%|██████████| 3000/3000 [00:06<00:00, 449.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0 loss: 4.267916679382324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #1: 100%|██████████| 3000/3000 [00:09<00:00, 317.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #1 loss: 4.267916679382324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #2: 100%|██████████| 3000/3000 [00:08<00:00, 334.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #2 loss: 4.267916679382324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #3: 100%|██████████| 3000/3000 [00:07<00:00, 412.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #3 loss: 4.267916679382324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempt #4: 100%|██████████| 3000/3000 [00:08<00:00, 354.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #4 loss: 4.267916679382324\n",
      "fin input: tensor([-2.5934, -2.6062,  5.3710, -5.6458,  0.2409, -2.3132, -3.6352, -4.3053])\n",
      "fin input (sigm): tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 2.8026e-45, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00])\n",
      "fin output: tensor([3.8542e-08, 1.1380e-04, 1.0000e+00, 3.7337e-05])\n",
      "fin loss: 4.267916679382324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ANTI_NET_STEPS = 3000\n",
    "TEST_EXAMPLES = 5\n",
    "TEST_TRIES = 5\n",
    "\n",
    "for i in range(5):\n",
    "    desired_input = test_x[i]\n",
    "    desired_output = test_y[i]\n",
    "\n",
    "    print(f'-=-=- step {i} -=-=-')\n",
    "    print(f'desired output:', desired_output)\n",
    "    print(f'example  input:', desired_input)\n",
    "\n",
    "    fin_loss = float('+inf')\n",
    "    fin_outp, fin_inp = None, None\n",
    "\n",
    "    for try_i in range(TEST_TRIES):\n",
    "        anti_net = AntiNet(model, (DIGITS * 2,), desired_output,\n",
    "                       input_min=0.0, input_max=1.0,\n",
    "                       lr=5e-2,\n",
    "                       temp_start=1.0, temp_end=0.05)\n",
    "\n",
    "        for step_i in tqdm.tqdm(range(ANTI_NET_STEPS), f'attempt #{try_i}'):\n",
    "            inp, outp, loss = anti_net.step(step_i, ANTI_NET_STEPS)\n",
    "\n",
    "        if loss.item() < fin_loss:\n",
    "            fin_loss = loss.item()\n",
    "            fin_outp = outp\n",
    "            fin_inp = inp\n",
    "        \n",
    "        print(f'attempt #{try_i} loss:', loss.item())\n",
    "\n",
    "    print(f'fin input:', fin_inp)\n",
    "    print(f'fin input (sigm):', anti_net.norm_func(fin_inp / anti_net.temp_end))\n",
    "    print(f'fin output:', fin_outp)\n",
    "    print(f'fin loss:', fin_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
