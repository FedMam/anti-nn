{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d70c12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a0517fee370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import math\n",
    "import tqdm\n",
    "from typing import *\n",
    "\n",
    "random.seed(192837)\n",
    "torch.manual_seed(192838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf54f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARAMS = 4\n",
    "N_DATA = 5000\n",
    "SAMPLES_SPLIT = 0.95\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "def FORMULA(params: Iterable[float]):\n",
    "    a, b, c, d = params\n",
    "    \n",
    "    return 0.0537 + \\\n",
    "           0.234 * a + \\\n",
    "           -0.51 * b + \\\n",
    "           0.112 * c + \\\n",
    "           -0.1633 * d + \\\n",
    "           -0.857 * a**2 + \\\n",
    "           0.117 * b**2 + \\\n",
    "           0.9 * a * b + \\\n",
    "           -0.363 * c**2 + \\\n",
    "           -0.103 * d**2 + \\\n",
    "           -0.5 * c*d + \\\n",
    "           1.2 * a*b*c*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8687ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 hidden_layers: int,\n",
    "                 output_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.foot = nn.Linear(input_dim, hidden_dim)\n",
    "        self.body = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(hidden_layers)])\n",
    "        self.head = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.foot(x))\n",
    "        for layer in self.body:\n",
    "            x = self.act(layer(x))\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49aa383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 250, 4275, 475)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = torch.rand(size=(N_DATA, N_PARAMS))\n",
    "\n",
    "n_leftout = round(N_DATA * (1 - SAMPLES_SPLIT))\n",
    "dataset_leftout, dataset = dataset[:n_leftout, :], dataset[n_leftout:, :]\n",
    "\n",
    "n_train = round((N_DATA - n_leftout) * TRAIN_TEST_SPLIT)\n",
    "n_test = N_DATA - n_leftout - n_train\n",
    "dataset_train, dataset_test = dataset[:n_train, :], dataset[n_train:, :]\n",
    "\n",
    "dataset_train_y = torch.tensor([FORMULA(dataset_train[i]) for i in range(n_train)])\n",
    "dataset_test_y = torch.tensor([FORMULA(dataset_test[i]) for i in range(n_test)])\n",
    "\n",
    "N_DATA, n_leftout, n_train, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444ae919",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train_epoch(model: nn.Module, optimizer: optim.Optimizer, dataset_x: torch.Tensor, dataset_y: torch.Tensor, batch_size=BATCH_SIZE):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    n_batches = math.ceil(dataset_x.shape[0] / batch_size)\n",
    "\n",
    "    for i in tqdm.tqdm(range(n_batches), 'train'):\n",
    "        x, y = dataset_x[i * batch_size: (i+1) * batch_size, :], dataset_y[i * batch_size: (i+1) * batch_size]\n",
    "        y_hat = model.forward(x).squeeze(dim=1)\n",
    "\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss_sum += loss.detach().clone()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return loss_sum / n_batches\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def test_epoch(model: nn.Module, dataset_x: torch.Tensor, dataset_y: torch.Tensor, batch_size=BATCH_SIZE):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        n_batches = math.ceil(dataset_x.shape[0] / batch_size)\n",
    "\n",
    "        for i in tqdm.tqdm(range(n_batches), ' test'):\n",
    "            x, y = dataset_x[i * batch_size: (i+1) * batch_size, :], dataset_y[i * batch_size: (i+1) * batch_size]\n",
    "            y_hat = model.forward(x).squeeze(dim=1)\n",
    "\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss_sum += loss\n",
    "        \n",
    "        return loss_sum / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b2828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=N_PARAMS, hidden_dim=8, hidden_layers=3, output_dim=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "N_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a19996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 267.26it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 3328.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.025589799508452415\n",
      " test loss: 0.007275852840393782\n",
      "=== epoch 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 245.92it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2845.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.004866989329457283\n",
      " test loss: 0.004260052461177111\n",
      "=== epoch 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 222.08it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 1405.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.003849201137199998\n",
      " test loss: 0.003741301130503416\n",
      "=== epoch 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 221.78it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2471.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.003602651646360755\n",
      " test loss: 0.003625196870416403\n",
      "=== epoch 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 197.79it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2233.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.00339615810662508\n",
      " test loss: 0.003737350460141897\n",
      "=== epoch 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 220.62it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 1813.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.003132794750854373\n",
      " test loss: 0.003523388411849737\n",
      "=== epoch 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 205.36it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 1749.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0027917474508285522\n",
      " test loss: 0.003238195786252618\n",
      "=== epoch 7 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 211.93it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 3146.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.002421214012429118\n",
      " test loss: 0.002887919545173645\n",
      "=== epoch 8 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 219.60it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 1353.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0020620531868189573\n",
      " test loss: 0.002621087711304426\n",
      "=== epoch 9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 239.34it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2771.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0017867962596938014\n",
      " test loss: 0.002090037800371647\n",
      "=== epoch 10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 254.22it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2708.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0016118374187499285\n",
      " test loss: 0.0015880054561421275\n",
      "=== epoch 11 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 264.30it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 1478.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0014972137287259102\n",
      " test loss: 0.001404574722982943\n",
      "=== epoch 12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 284.09it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2840.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0014407869894057512\n",
      " test loss: 0.0013549705035984516\n",
      "=== epoch 13 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 275.87it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2517.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0014071118785068393\n",
      " test loss: 0.0013300826540216804\n",
      "=== epoch 14 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:02<00:00, 264.05it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2659.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0013937745243310928\n",
      " test loss: 0.0013374699046835303\n",
      "=== epoch 15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 279.80it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2798.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0013844959903508425\n",
      " test loss: 0.0013336432166397572\n",
      "=== epoch 16 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 275.98it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 3004.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0013762477319687605\n",
      " test loss: 0.001321546034887433\n",
      "=== epoch 17 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 269.18it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2186.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0013641368132084608\n",
      " test loss: 0.0013064087834209204\n",
      "=== epoch 18 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 282.48it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2754.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0013568371068686247\n",
      " test loss: 0.0012916355626657605\n",
      "=== epoch 19 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 535/535 [00:01<00:00, 270.45it/s]\n",
      " test: 100%|██████████| 60/60 [00:00<00:00, 2953.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.001349085010588169\n",
      " test loss: 0.001299887546338141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(N_EPOCHS):\n",
    "    print(f'=== epoch {epoch_i} ===')\n",
    "\n",
    "    train_loss = train_epoch(model, optimizer, dataset_train, dataset_train_y)\n",
    "    test_loss = test_epoch(model, dataset_test, dataset_test_y)\n",
    "\n",
    "    print('train loss:', train_loss.item())\n",
    "    print(' test loss:', test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f83cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntiNet():\n",
    "    def __init__(self,\n",
    "               inner_net: nn.Module,\n",
    "               input_shape: torch.Size,\n",
    "               desired_output: torch.Tensor,\n",
    "               lr: float=1e-2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.input = nn.Parameter(\n",
    "            data=torch.normal(mean=0.0, std=1.0, size=self.input_shape),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.inner_net = inner_net\n",
    "        self.grad_eraser = torch.optim.SGD(self.inner_net.parameters())\n",
    "        self.anti_optimizer = torch.optim.Adam((self.input,), lr=lr)\n",
    "        self.desired_output = desired_output\n",
    "        self.output_shape = self.desired_output.shape\n",
    "\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            return self.inner_net.forward(self.input)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.grad_eraser.zero_grad()\n",
    "        self.anti_optimizer.zero_grad()\n",
    "    \n",
    "    def step(self):\n",
    "        prev_input = self.input.detach().clone()\n",
    "\n",
    "        output = self.inner_net.forward(self.input)\n",
    "        loss = F.mse_loss(output, self.desired_output)\n",
    "\n",
    "        loss.backward()\n",
    "        self.anti_optimizer.step()\n",
    "        self.zero_grad()\n",
    "\n",
    "        return prev_input, output.detach().clone(), loss.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf236cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=- step 0 -=-=-\n",
      "des  input: tensor([0.4501, 0.8621, 0.2806, 0.9874])\n",
      "des output: tensor([-0.2865])\n",
      "fin  input: tensor([-0.2922, -0.3643,  1.1482, -0.2821])\n",
      "fin output: tensor([-0.2865])\n",
      "fin loss: tensor(7.9936e-15)\n",
      "-=-=- step 1 -=-=-\n",
      "des  input: tensor([0.0962, 0.1024, 0.4580, 0.9973])\n",
      "des output: tensor([-0.4870])\n",
      "fin  input: tensor([-0.9342,  1.2046, -1.0785, -0.0882])\n",
      "fin output: tensor([-0.4870])\n",
      "fin loss: tensor(2.2204e-14)\n",
      "-=-=- step 2 -=-=-\n",
      "des  input: tensor([0.0156, 0.9726, 0.8447, 0.8128])\n",
      "des output: tensor([-1.0106])\n",
      "fin  input: tensor([-0.4207,  0.7653,  0.4533,  0.6726])\n",
      "fin output: tensor([-1.0106])\n",
      "fin loss: tensor(0.)\n",
      "-=-=- step 3 -=-=-\n",
      "des  input: tensor([0.0163, 0.5209, 0.9359, 0.4601])\n",
      "des output: tensor([-0.6900])\n",
      "fin  input: tensor([-0.9574,  0.3982,  1.7066, -1.6092])\n",
      "fin output: tensor([-0.6900])\n",
      "fin loss: tensor(3.5527e-15)\n",
      "-=-=- step 4 -=-=-\n",
      "des  input: tensor([0.1960, 0.8433, 0.5908, 0.4873])\n",
      "des output: tensor([-0.3829])\n",
      "fin  input: tensor([-0.8491,  0.6009,  0.0454, -0.6389])\n",
      "fin output: tensor([-0.3829])\n",
      "fin loss: tensor(3.1974e-14)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    desired_input = dataset_leftout[i]\n",
    "    desired_output = torch.tensor([FORMULA(desired_input)])\n",
    "\n",
    "    desired_input, desired_output\n",
    "\n",
    "    anti_net = AntiNet(model, (N_PARAMS,), desired_output)\n",
    "    ANTI_NET_STEPS = 300\n",
    "\n",
    "    print(f'-=-=- step {i} -=-=-')\n",
    "    print(f'des  input:', desired_input)\n",
    "    print(f'des output:', desired_output)\n",
    "\n",
    "    for step_i in range(ANTI_NET_STEPS):\n",
    "        inp, outp, loss = anti_net.step()\n",
    "    \n",
    "    print(f'fin  input:', inp)\n",
    "    print(f'fin output:', outp)\n",
    "    print(f'fin loss:', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
